{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaa6988-2ab5-4552-97b5-1e84e308ceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import fbeta_score, make_scorer, accuracy_score,  confusion_matrix, cohen_kappa_score, precision_score, recall_score, classification_report, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder,  StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor,AdaBoostRegressor, GradientBoostingRegressor, AdaBoostClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, root_mean_squared_error\n",
    "\n",
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "import time\n",
    "\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e8c0e-5dca-44de-9158-3b41073ae946",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data = \"../data/clean/resampled_data.csv\"\n",
    "heart_df = pd.read_csv(heart_data)\n",
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daad077-6721-4f26-ae00-7f3a59dea7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f4542-0ea3-4835-8cc7-dfe03c3c2759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = heart_df.drop(['PhysHlth', 'DiffWalk','Education'],  axis=1)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c609d-0abd-468b-80f5-d67dcc61e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=heart_df, x='HeartDiseaseorAttack')\n",
    "plt.title(f'Count plot')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels if needed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6fd55-63a3-4c8a-ac26-be251ea4d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_new['HeartDiseaseorAttack']\n",
    "features = df_new.drop('HeartDiseaseorAttack', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.20, random_state=0)\n",
    "\n",
    "#Normalise all columns to be 0-1\n",
    "normalizer = MinMaxScaler()\n",
    "normalizer.fit(x_train)\n",
    "\n",
    "x_train_norm = normalizer.transform(x_train)\n",
    "x_test_norm = normalizer.transform(x_test)\n",
    "\n",
    "x_train_norm = pd.DataFrame(x_train_norm, columns=x_train.columns, index=x_train.index )\n",
    "x_test_norm = pd.DataFrame(x_test_norm, columns=x_test.columns, index=x_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0100b91b-4dc7-42c9-8729-f8e877401291",
   "metadata": {},
   "source": [
    "#### Adaptive boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e7ec03-80b4-4833-9ea8-d80543f6a24e",
   "metadata": {},
   "source": [
    "#### Using classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd62a5b-dd12-4376-8f86-7b058f9970e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_reg = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20),\n",
    "                            n_estimators=100, algorithm='SAMME')\n",
    "ada_reg.fit(x_train_norm, y_train)\n",
    "pred = ada_reg.predict(x_test_norm)\n",
    "print(f\"MAE, {mean_absolute_error(pred, y_test): .2f}\")\n",
    "print(f\"MSE, {mean_squared_error(pred, y_test): .2f}\")\n",
    "print(f\"RMSE, {root_mean_squared_error(pred, y_test): .2f}\")\n",
    "print(f\"R2 score, {ada_reg.score(x_test_norm, y_test): .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ae43a3-abbe-4890-be53-7a2ebb9e7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_normalised_data(df_new):\n",
    "    \"\"\"\n",
    "    Split the dataset into target and features, then divide it into train and test.\n",
    "    Apply Min-Max Scaling to normalize the feature values to a range of 0 to 1 for both train and test.\n",
    "    Iterates over a range of n_estimators (from 6 to 14) to train an AdaBoost classifier, decision tree base(max depth = 20)\n",
    "    Uses the SAMME algorithm for boosting.\n",
    "    For each iteration, calculates accuracy, recall, and Cohen's Kappa score.\n",
    "    Stores the results into a dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    target = df_new['HeartDiseaseorAttack']\n",
    "    features = df_new.drop('HeartDiseaseorAttack', axis=1)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.20, random_state=0)\n",
    "    \n",
    "    #Normalise all columns to be 0-1\n",
    "    normalizer = MinMaxScaler()\n",
    "    normalizer.fit(x_train)\n",
    "    \n",
    "    x_train_norm = normalizer.transform(x_train)\n",
    "    x_test_norm = normalizer.transform(x_test)\n",
    "    \n",
    "    x_train_norm = pd.DataFrame(x_train_norm, columns=x_train.columns, index=x_train.index )\n",
    "    x_test_norm = pd.DataFrame(x_test_norm, columns=x_test.columns, index=x_test.index)\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    \n",
    "    # Iterate over a range of n_estimators for AdaBoost\n",
    "    for i in range(2,25): \n",
    "        ada_boost = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20),\n",
    "            n_estimators=i,  # number of estimators (trees)\n",
    "            algorithm='SAMME'\n",
    "        )\n",
    "        \n",
    "        # Fit the AdaBoost model\n",
    "        ada_boost.fit(x_train, y_train)\n",
    "        # Predict the labels on the test set\n",
    "        y_pred = ada_boost.predict(x_test)\n",
    "        \n",
    "        # Calculate Cohen's Kappa score\n",
    "        kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    \n",
    "        #Calculate the recall\n",
    "        recall = recall_score(y_test, y_pred) * 100\n",
    "        \n",
    "        # Calculate accuracy manually using confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = 100 * ((cm[0][0] + cm[1][1]) / (sum(cm[0]) + sum(cm[1])))\n",
    "\n",
    "        print(f\"AdaBoost Test MAE: {mean_absolute_error(y_test, y_pred): .4f}\")\n",
    "        print(f\"AdaBoost Test MSE: {mean_squared_error(y_test, y_pred): .4f}\")\n",
    "        print(f\"AdaBoost Test RMSE: {root_mean_squared_error(y_test, y_pred): .4f}\")\n",
    "        print(f\"AdaBoost Test R2 score: {ada_boost.score(x_test_norm, y_test): .4f}\")\n",
    "        print()\n",
    "        \n",
    "        results.append({\n",
    "            \"k\": i,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Recall\": recall,\n",
    "            \"Kappa\": kappa\n",
    "        })\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddd5523-d8c5-45e6-a135-2c10346417c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df =test_normalised_data(df_new)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945b98de-2982-4b4f-ac5c-75879eaddf42",
   "metadata": {},
   "source": [
    "#### Interpretation of the result\n",
    "\n",
    "The MAE, MSE, and RMSE values suggest relatively small prediction errors, indicating that the model's predictions are quite close to the actual values.\n",
    "\n",
    "#### General Performance:\n",
    "\n",
    "- Accuracy improved with more neighbours, peaking at 74.70% in k=23 (estimators)\n",
    "- Consistently improved, reaching a peak of 77.02% at k=20 making it critical for detecting true positives in heart attack risk prediction.\n",
    "- Achieved its highest value of 0.4941 at k=23, indicating better agreement between predictions and actual values.\n",
    "\n",
    "#### Best Configuration:\n",
    "\n",
    "- 23 estimators provided the best results:\n",
    "- Accuracy: 74.70%\n",
    "- Recall: 76.94%\n",
    "- Cohenâ€™s Kappa: 0.4941\n",
    "\n",
    "This configuration achieved the highest recall and Cohen's Kappa, balancing predictive accuracy and medical relevance.\n",
    "\n",
    "Recall improvement is notable, reaching a peak of 77.02% at k=20, making it critical for detecting true positives in heart attack risk prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6068d6-d254-4d5b-b014-aebcb2054c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# Melt the DataFrame for easier plotting with Plotly\n",
    "df_melted = scores_df.melt(id_vars=\"k\", value_vars=[\"Accuracy\", \"Recall\"], \n",
    "                    var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "# Create the line plot with Plotly Express\n",
    "fig = px.line(df_melted, x=\"k\", y=\"Score\", color=\"Metric\", markers=True,\n",
    "              title=\"Model Performance Metrics vs. k (Number of Estimators)\",\n",
    "              labels={\"k\": \"Number of Estimators (k)\", \"Score\": \"Metric Score\"})\n",
    "\n",
    "# Customize the layout for better presentation\n",
    "fig.update_layout(\n",
    "    title_font_size=20,\n",
    "    xaxis_title=\"Number of Estimators (k)\",\n",
    "    yaxis_title=\"Metric Score in %\",\n",
    "    template=\"plotly_white\",\n",
    "    legend_title=\"Metrics\",\n",
    "    xaxis=dict(tickmode=\"linear\"),\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd61b855-f3b3-451d-8814-d38bba64a9c7",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37e5f7-6850-4c42-9f26-8c491d0a1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6762cea-0e1f-4b47-8307-cb4818e3fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.score(x_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad310d3-e9d0-43e4-8138-f13efaf41da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = log_reg.predict(x_test_norm)\n",
    "print(classification_report(y_pred = pred, y_true = y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c6db17-30e0-4903-b012-c47208ca182f",
   "metadata": {},
   "source": [
    "#### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbfc2ae-9c88-4237-9b63-bda031978cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import scipy.stats as st\n",
    "\n",
    "# First we need to setup a dictionary with all the values that we want to try for each hyprerparameter\n",
    "\n",
    "parameter_grid = {\"max_depth\": [10, 50],\n",
    "                  \"min_samples_split\": [4, 16],\n",
    "                  \"max_leaf_nodes\": [250, 100],\n",
    "                  \"max_features\": [\"sqrt\", \"log2\"]} # In example we're going to test 2 * 2 * 2 * 2 = 16 combinations of hyperparameters\n",
    "\n",
    "# We create an instance or our machine learning model\n",
    "dt = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "# We need to set this two variables to be able to compute a confidence interval\n",
    "confidence_level = 0.95\n",
    "folds = 10\n",
    "\n",
    "# Now we need to create an intance of the GridSearchCV class\n",
    "gs = GridSearchCV(dt, param_grid=parameter_grid, cv=folds, verbose=10) # Here the \"cv\" allows you to define the number of folds to use.\n",
    "\n",
    "start_time = time.time()\n",
    "gs.fit(x_train_norm, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Time taken to find the best combination of hyperparameters among the given ones: {end_time - start_time: .4f} seconds\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(f\"The best combination of hyperparameters has been: {gs.best_params_}\")\n",
    "print(f\"The R2 is: {gs.best_score_: .4f}\")\n",
    "\n",
    "results_gs_df = pd.DataFrame(gs.cv_results_).sort_values(by=\"mean_test_score\", ascending=False)\n",
    "\n",
    "#print(results_df.head())\n",
    "gs_mean_score = results_gs_df.iloc[0,-3]\n",
    "gs_sem = results_gs_df.iloc[0,-2] / np.sqrt(10)\n",
    "\n",
    "gs_tc = st.t.ppf(1-((1-confidence_level)/2), df=folds-1)\n",
    "gs_lower_bound = gs_mean_score - ( gs_tc * gs_sem )\n",
    "gs_upper_bound = gs_mean_score + ( gs_tc * gs_sem )\n",
    "\n",
    "print(f\"The R2 confidence interval for the best combination of hyperparameters is: \\\n",
    "    ({gs_lower_bound: .4f}, {gs_mean_score: .4f}, {gs_upper_bound: .4f}) \")\n",
    "\n",
    "#display(results_df)\n",
    "\n",
    "# Let's store the best model\n",
    "best_model = gs.best_estimator_\n",
    "\n",
    "# Now is time evaluate the model in the test set\n",
    "y_pred_test_df = best_model.predict(x_test_norm)\n",
    "y_pred_test_df = best_model.predict(x_test_norm)\n",
    "\n",
    "y_pred_test_df = best_model.predict(x_test_norm)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Test MAE: {mean_absolute_error(y_pred_test_df, y_test): .4f}\")\n",
    "print(f\"Test MSE: {mean_squared_error(y_pred_test_df, y_test): .4f}\")\n",
    "print(f\"Test RMSE: {root_mean_squared_error(y_pred_test_df, y_test): .4f}\")\n",
    "print(f\"Test R2 score:  {best_model.score(x_test_norm, y_test): .4f}\")\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a228a26-23d1-4f84-b686-347b30e53dfc",
   "metadata": {},
   "source": [
    "#### Bayesian search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d15fa7e-4703-4233-b528-c0d936a0a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, confidence_level, folds):\n",
    "\n",
    "    # First, we define the grid with values to consider when train several possible combinations.\n",
    "    # Now we specify a range/list of values to try for each hyper-parameter, and we let optuna to decide which\n",
    "    # combination to try.\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 10, 50)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 4, 16)\n",
    "    max_leaf_nodes = trial.suggest_int(\"max_leaf_nodes\", 250, 1000)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"])\n",
    "\n",
    "    dt = DecisionTreeClassifier(random_state=123,\n",
    "                               max_depth=max_depth,\n",
    "                               min_samples_split=min_samples_split,\n",
    "                               max_leaf_nodes=max_leaf_nodes,\n",
    "                               max_features=max_features)\n",
    "\n",
    "    # Here the parameter \"cv\" specifies the number of folds K\n",
    "    scores = cross_val_score(dt, x_train_norm, y_train, cv=folds) # The scores provided will be the R2 on each hold out fold\n",
    "    mean_score = np.mean(scores)\n",
    "    sem = np.std(scores, ddof=1) / np.sqrt(folds)\n",
    "\n",
    "    tc = st.t.ppf(1-((1-confidence_level)/2), df=folds-1)\n",
    "    lower_bound = mean_score - ( tc * sem )\n",
    "    upper_bound = mean_score + ( tc * sem )\n",
    "\n",
    "    # Here, we're storing confidence interval for each trial. It's not possible for the objective function to return\n",
    "    # multiple values as Optuna uses the only returned value to find the best combination of hyperparameters.\n",
    "    trial.set_user_attr(\"CV_score_summary\", [round(lower_bound,4), round(np.mean(scores),4), round(upper_bound,4)])\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d39aa87-9639-416f-9658-8993dfb9ab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_level = 0.95\n",
    "folds = 10\n",
    "\n",
    "start_time = time.time()\n",
    "study = optuna.create_study(direction=\"maximize\") # We want to have the maximum values for the R2 scores\n",
    "study.optimize(lambda trial: objective(trial, confidence_level, folds), n_trials=45)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Time taken to find the best combination of hyperparameters among the given ones: {end_time - start_time: .4f} seconds\")\n",
    "print(\"\\n\")\n",
    "print(\"The best combination of hyperparameters found was: \", study.best_params)\n",
    "print(f\"The best R2 found was: {study.best_value: .4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
