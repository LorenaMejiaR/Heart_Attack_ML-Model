{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaa6988-2ab5-4552-97b5-1e84e308ceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import fbeta_score, make_scorer, accuracy_score,  confusion_matrix, cohen_kappa_score, precision_score, recall_score, classification_report, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder,  StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor,AdaBoostRegressor, GradientBoostingRegressor, AdaBoostClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, root_mean_squared_error\n",
    "\n",
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "import time\n",
    "\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e8c0e-5dca-44de-9158-3b41073ae946",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data = \"../data/clean/resampled_data.csv\"\n",
    "heart_df = pd.read_csv(heart_data)\n",
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daad077-6721-4f26-ae00-7f3a59dea7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f4542-0ea3-4835-8cc7-dfe03c3c2759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = heart_df.drop(['PhysHlth', 'DiffWalk','Education'],  axis=1)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c609d-0abd-468b-80f5-d67dcc61e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=heart_df, x='HeartDiseaseorAttack')\n",
    "plt.title(f'Count plot')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels if needed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6fd55-63a3-4c8a-ac26-be251ea4d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_new['HeartDiseaseorAttack']\n",
    "features = df_new.drop('HeartDiseaseorAttack', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.20, random_state=0)\n",
    "\n",
    "#Normalise all columns to be 0-1\n",
    "normalizer = MinMaxScaler()\n",
    "normalizer.fit(x_train)\n",
    "\n",
    "x_train_norm = normalizer.transform(x_train)\n",
    "x_test_norm = normalizer.transform(x_test)\n",
    "\n",
    "x_train_norm = pd.DataFrame(x_train_norm, columns=x_train.columns, index=x_train.index )\n",
    "x_test_norm = pd.DataFrame(x_test_norm, columns=x_test.columns, index=x_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0100b91b-4dc7-42c9-8729-f8e877401291",
   "metadata": {},
   "source": [
    "#### Adaptive boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e7ec03-80b4-4833-9ea8-d80543f6a24e",
   "metadata": {},
   "source": [
    "#### Using classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd62a5b-dd12-4376-8f86-7b058f9970e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_reg = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20),\n",
    "                            n_estimators=100, algorithm='SAMME')\n",
    "ada_reg.fit(x_train_norm, y_train)\n",
    "pred = ada_reg.predict(x_test_norm)\n",
    "print(f\"MAE, {mean_absolute_error(pred, y_test): .2f}\")\n",
    "print(f\"MSE, {mean_squared_error(pred, y_test): .2f}\")\n",
    "print(f\"RMSE, {root_mean_squared_error(pred, y_test): .2f}\")\n",
    "print(f\"R2 score, {ada_reg.score(x_test_norm, y_test): .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ae43a3-abbe-4890-be53-7a2ebb9e7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_normalised_data(df_new):\n",
    "    \"\"\"\n",
    "    Split the dataset into target and features, then divide it into train and test.\n",
    "    Apply Min-Max Scaling to normalize the feature values to a range of 0 to 1 for both train and test.\n",
    "    Iterates over a range of n_estimators (from 6 to 14) to train an AdaBoost classifier, decision tree base(max depth = 20)\n",
    "    Uses the SAMME algorithm for boosting.\n",
    "    For each iteration, calculates accuracy, recall, and Cohen's Kappa score.\n",
    "    Stores the results into a dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    target = df_new['HeartDiseaseorAttack']\n",
    "    features = df_new.drop('HeartDiseaseorAttack', axis=1)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.20, random_state=0)\n",
    "    \n",
    "    #Normalise all columns to be 0-1\n",
    "    normalizer = MinMaxScaler()\n",
    "    normalizer.fit(x_train)\n",
    "    \n",
    "    x_train_norm = normalizer.transform(x_train)\n",
    "    x_test_norm = normalizer.transform(x_test)\n",
    "    \n",
    "    x_train_norm = pd.DataFrame(x_train_norm, columns=x_train.columns, index=x_train.index )\n",
    "    x_test_norm = pd.DataFrame(x_test_norm, columns=x_test.columns, index=x_test.index)\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    \n",
    "    # Iterate over a range of n_estimators for AdaBoost\n",
    "    for i in range(2,25): \n",
    "        ada_boost = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20),\n",
    "            n_estimators=i,  # number of estimators (trees)\n",
    "            algorithm='SAMME'\n",
    "        )\n",
    "        \n",
    "        # Fit the AdaBoost model\n",
    "        ada_boost.fit(x_train, y_train)\n",
    "        # Predict the labels on the test set\n",
    "        y_pred = ada_boost.predict(x_test)\n",
    "        \n",
    "        # Calculate Cohen's Kappa score\n",
    "        kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    \n",
    "        #Calculate the recall\n",
    "        recall = recall_score(y_test, y_pred) * 100\n",
    "        \n",
    "        # Calculate accuracy manually using confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        accuracy = 100 * ((cm[0][0] + cm[1][1]) / (sum(cm[0]) + sum(cm[1])))\n",
    "\n",
    "        print(f\"AdaBoost Test MAE: {mean_absolute_error(y_test, y_pred): .4f}\")\n",
    "        print(f\"AdaBoost Test MSE: {mean_squared_error(y_test, y_pred): .4f}\")\n",
    "        print(f\"AdaBoost Test RMSE: {root_mean_squared_error(y_test, y_pred): .4f}\")\n",
    "        print(f\"AdaBoost Test R2 score: {ada_boost.score(x_test_norm, y_test): .4f}\")\n",
    "        print()\n",
    "        \n",
    "        results.append({\n",
    "            \"k\": i,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Recall\": recall,\n",
    "            \"Kappa\": kappa\n",
    "        })\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddd5523-d8c5-45e6-a135-2c10346417c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the result in df\n",
    "scores_df =test_normalised_data(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945b98de-2982-4b4f-ac5c-75879eaddf42",
   "metadata": {},
   "source": [
    "#### Interpretation of the result\n",
    "\n",
    "The MAE, MSE, and RMSE values suggest relatively small prediction errors, indicating that the model's predictions are quite close to the actual values.\n",
    "\n",
    "#### General Performance:\n",
    "\n",
    "- Accuracy improved with more neighbours, peaking at 74.70% in k=23 (estimators)\n",
    "- Consistently improved, reaching a peak of 77.02% at k=20 making it critical for detecting true positives in heart attack risk prediction.\n",
    "- Achieved its highest value of 0.4941 at k=23, indicating better agreement between predictions and actual values.\n",
    "\n",
    "#### Best Configuration:\n",
    "\n",
    "- 23 estimators provided the best results:\n",
    "- Accuracy: 74.70%\n",
    "- Recall: 76.94%\n",
    "- Cohenâ€™s Kappa: 0.4941\n",
    "\n",
    "This configuration achieved the highest recall and Cohen's Kappa, balancing predictive accuracy and medical relevance.\n",
    "\n",
    "Recall improvement is notable, reaching a peak of 77.02% at k=20, making it critical for detecting true positives in heart attack risk prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6068d6-d254-4d5b-b014-aebcb2054c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# Melt the DataFrame for easier plotting with Plotly\n",
    "df_melted = scores_df.melt(id_vars=\"k\", value_vars=[\"Accuracy\", \"Recall\"], \n",
    "                    var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "# Create the line plot with Plotly Express\n",
    "fig = px.line(df_melted, x=\"k\", y=\"Score\", color=\"Metric\", markers=True,\n",
    "              title=\"Model Performance Metrics vs. k (Number of Estimators)\",\n",
    "              labels={\"k\": \"Number of Estimators (k)\", \"Score\": \"Metric Score\"})\n",
    "\n",
    "# Customize the layout for better presentation\n",
    "fig.update_layout(\n",
    "    title_font_size=20,\n",
    "    xaxis_title=\"Number of Estimators (k)\",\n",
    "    yaxis_title=\"Metric Score\",\n",
    "    template=\"plotly_white\",\n",
    "    legend_title=\"Metrics\",\n",
    "    xaxis=dict(tickmode=\"linear\"),\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd61b855-f3b3-451d-8814-d38bba64a9c7",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37e5f7-6850-4c42-9f26-8c491d0a1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6762cea-0e1f-4b47-8307-cb4818e3fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.score(x_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad310d3-e9d0-43e4-8138-f13efaf41da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = log_reg.predict(x_test_norm)\n",
    "report_dict = classification_report(y_true=y_test, y_pred=pred, output_dict=True)\n",
    "\n",
    "# Convert the dictionary to a pandas DataFrame\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "# Reset index for plotting\n",
    "report_df = report_df.reset_index()\n",
    "\n",
    "# Filter out 'accuracy' and 'macro avg' for class-level plotting\n",
    "filtered_df = report_df[~report_df['index'].isin(['accuracy', 'macro avg', 'weighted avg'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757a64c0-0e6a-4f94-baed-558e62a7bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare data for Plotly\n",
    "filtered_metrics_plotly = filtered_df.melt(\n",
    "    id_vars='index', \n",
    "    value_vars=metrics, \n",
    "    var_name='Metric', \n",
    "    value_name='Score'\n",
    ")\n",
    "\n",
    "# Create an interactive bar chart\n",
    "fig = px.bar(\n",
    "    filtered_metrics_plotly,\n",
    "    x='index',\n",
    "    y='Score',\n",
    "    color='Metric',\n",
    "    barmode='group',\n",
    "    labels={'index': 'Class', 'Score': 'Score'}\n",
    ")\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Class\",\n",
    "    yaxis_title=\"Score\",\n",
    "    yaxis=dict(range=[0, 1]),\n",
    "    legend_title=\"Metric\",\n",
    "    title_font_size=20\n",
    ")\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a228a26-23d1-4f84-b686-347b30e53dfc",
   "metadata": {},
   "source": [
    "#### Bayesian search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea6e049-010d-4864-b9ac-1034fa6028a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, confidence_level, folds):\n",
    "    # Define the range of hyperparameters for AdaBoost\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 10, 200)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 1.0, log=True)  # Updated for Optuna v3.0\n",
    "    algorithm = trial.suggest_categorical(\"algorithm\", [\"SAMME\"])  # Use SAMME to avoid deprecation issues\n",
    "\n",
    "    # Define the base estimator for AdaBoost\n",
    "    base_estimator = DecisionTreeClassifier(\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        random_state=123\n",
    "    )\n",
    "\n",
    "    # Define the AdaBoost model\n",
    "    ada_boost = AdaBoostClassifier(\n",
    "        estimator=base_estimator,\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        algorithm=algorithm,\n",
    "        random_state=123\n",
    "    )\n",
    "\n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(ada_boost, x_train_norm, y_train, cv=folds, scoring='recall')\n",
    "    mean_score = np.mean(scores)\n",
    "    sem = np.std(scores, ddof=1) / np.sqrt(folds)\n",
    "\n",
    "    # Calculate confidence interval\n",
    "    tc = st.t.ppf(1-((1-confidence_level)/2), df=folds-1)\n",
    "    lower_bound = mean_score - (tc * sem)\n",
    "    upper_bound = mean_score + (tc * sem)\n",
    "\n",
    "    # Store confidence interval for the trial\n",
    "    trial.set_user_attr(\"CV_score_summary\", [round(lower_bound, 4), round(mean_score, 4), round(upper_bound, 4)])\n",
    "\n",
    "    return mean_score  # Return the mean recall score\n",
    "\n",
    "\n",
    "# optuna study is created to optimize hyperparameters for maximizing recall, using a custom objective function with 45 trials and a progress bar\n",
    "confidence_level = 0.95\n",
    "folds = 10\n",
    "\n",
    "start_time = time.time()\n",
    "study = optuna.create_study(direction=\"maximize\")  # maximize recall\n",
    "study.optimize(lambda trial: objective(trial, confidence_level, folds), n_trials=45, show_progress_bar=True)\n",
    "end_time = time.time()\n",
    "\n",
    "# Output results\n",
    "print(\"\\n\")\n",
    "#time taken for optimization is calculated and printed, together with the best combination of hyperparameters\n",
    "print(f\"Time taken to find the best combination of hyperparameters among the given ones: {end_time - start_time: .4f} seconds\")\n",
    "print(\"\\n\")\n",
    "print(\"The best combination of hyperparameters found was: \", study.best_params)\n",
    "# best recall score achieved during the optimization is displayed\n",
    "print(f\"The best Recall score found was: {study.best_value: .4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76873710-98d6-4044-8092-1e8338f73f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code extracts and sorts trials based on the upper bound of the Recall confidence interval to identify the best hyperparameter combination\n",
    "# prints the recall for the best performing trial and visualizes the optimization history\n",
    "results = sorted([(index,\n",
    "  trial.user_attrs['CV_score_summary'][0],\n",
    "  trial.user_attrs['CV_score_summary'][1],\n",
    "  trial.user_attrs['CV_score_summary'][2]) for index, trial in enumerate(study.trials)], key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(f\"The Recall confidence interval for the best combination of hyperparameters is: {results[0][1:]}\")\n",
    "vis.plot_optimization_history(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
