{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "106c32b6-89c8-4180-9235-c936477621c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier,AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, root_mean_squared_error, make_scorer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ef2ab15-0a01-46eb-97c3-f584079a1c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data = \"../data/clean/resampled_data.csv\"\n",
    "heart_df = pd.read_csv(heart_data)\n",
    "drop_df = heart_df.drop(['PhysHlth', 'DiffWalk','Education', 'Veggies'],  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b1f20db-21bf-4803-b415-3db8cc5aa266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing train split \n",
    "\n",
    "target = drop_df['HeartDiseaseorAttack']\n",
    "features = drop_df.drop('HeartDiseaseorAttack', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.20, random_state=0)\n",
    "\n",
    "target_base = heart_df['HeartDiseaseorAttack']\n",
    "features_base = heart_df.drop('HeartDiseaseorAttack', axis=1)\n",
    "\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(features_base, target_base, test_size=0.20, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a72bed40-7c81-4023-bef4-a62a3391ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalise all columns to be 0-1\n",
    "normalizer = MinMaxScaler()\n",
    "normalizer.fit(x_train)\n",
    "\n",
    "x_train_norm = normalizer.transform(x_train)\n",
    "x_test_norm = normalizer.transform(x_test)\n",
    "\n",
    "x_train_norm_df = pd.DataFrame(x_train_norm, columns=x_train.columns, index=x_train.index )\n",
    "x_test_norm_df = pd.DataFrame(x_test_norm, columns=x_test.columns, index=x_test.index)\n",
    "\n",
    "normalizer.fit(x_train2)\n",
    "\n",
    "x_train_norm2 = normalizer.transform(x_train2)\n",
    "x_test_norm2 = normalizer.transform(x_test2)\n",
    "\n",
    "x_train_norm_df2 = pd.DataFrame(x_train_norm2, columns=x_train2.columns, index=x_train2.index )\n",
    "x_test_norm_df2 = pd.DataFrame(x_test_norm2, columns=x_test2.columns, index=x_test2.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3567e20-ac1e-44cd-99f5-975d94a8e417",
   "metadata": {},
   "source": [
    "### KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e3876753-2e3f-425a-a99b-61b6c175b04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=23)\n",
    "knn.fit(x_train_norm_df, y_train)\n",
    "y_pred_knn = knn.predict(x_test_norm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "17a64d5a-307f-45cf-a21a-c3a42a66bcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.2370\n",
      "RMSE:  0.4868\n",
      "Recall:  0.7428\n",
      "Precision:  0.8028\n",
      "Kappa:  0.5262\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAE: {mean_absolute_error(y_pred_knn, y_test): .4f}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_pred_knn, y_test): .4f}\")\n",
    "print(f\"Recall: {recall_score(y_pred_knn, y_test): .4f}\")\n",
    "print(f\"Precision: {precision_score(y_pred_knn, y_test): .4f}\")\n",
    "print(f\"Kappa: {cohen_kappa_score(y_pred_knn, y_test): .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c34432f-9620-4864-82cb-7f67967e3f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.2555\n",
      "RMSE:  0.5055\n",
      "Recall:  0.7457\n",
      "Precision:  0.7400\n",
      "Kappa:  0.4890\n"
     ]
    }
   ],
   "source": [
    "knn.fit(x_train_norm_df2, y_train2)\n",
    "y_pred_knn2 = knn.predict(x_test_norm_df2)\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(y_pred_knn2, y_test2): .4f}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_pred_knn2, y_test2): .4f}\")\n",
    "print(f\"Recall: {recall_score(y_pred_knn2, y_test2): .4f}\")\n",
    "print(f\"Precision: {precision_score(y_pred_knn2, y_test2): .4f}\")\n",
    "print(f\"Kappa: {cohen_kappa_score(y_pred_knn2, y_test2): .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4e9e0a-a4d2-4f70-83e2-21715acb5845",
   "metadata": {},
   "source": [
    "### Random Forests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38dc6a27-5310-49fe-90eb-2d1619208a23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rf.fit(x_train_norm_df, y_train)\n",
    "y_pred_rf = rf.predict(x_test_norm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "183b08a4-4011-403e-9823-57d746615def",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.2425\n",
      "RMSE:  0.4925\n",
      "Recall:  0.7426\n",
      "Precision:  0.7862\n",
      "Kappa:  0.5150\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAE: {mean_absolute_error(y_pred_rf, y_test): .4f}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_pred_rf, y_test): .4f}\")\n",
    "print(f\"Recall: {recall_score(y_pred_rf, y_test): .4f}\")\n",
    "print(f\"Precision: {precision_score(y_pred_rf, y_test): .4f}\")\n",
    "print(f\"Kappa: {cohen_kappa_score(y_pred_rf, y_test): .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc46fd56-7c07-4ade-83c7-f6639ca611b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.2341\n",
      "RMSE:  0.4839\n",
      "Recall:  0.7477\n",
      "Precision:  0.8005\n",
      "Kappa:  0.5318\n"
     ]
    }
   ],
   "source": [
    "rf.fit(x_train_norm_df2, y_train2)\n",
    "y_pred_rf2 = rf.predict(x_test_norm_df2)\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(y_pred_rf2, y_test2): .4f}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_pred_rf2, y_test2): .4f}\")\n",
    "print(f\"Recall: {recall_score(y_pred_rf2, y_test2): .4f}\")\n",
    "print(f\"Precision: {precision_score(y_pred_rf2, y_test2): .4f}\")\n",
    "print(f\"Kappa: {cohen_kappa_score(y_pred_rf2, y_test2): .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c624b056-9526-4795-8a9e-67de12023068",
   "metadata": {},
   "source": [
    "### Gradient Boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5767520-779b-43cb-b5bc-1f19e5e7718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(max_depth=10, n_estimators=50)\n",
    "\n",
    "gb.fit(x_train_norm_df, y_train)\n",
    "y_pred_gb = gb.predict(x_test_norm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9277422-4940-43df-8382-73d9da59e0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.2332\n",
      "RMSE:  0.4829\n",
      "Recall:  0.7483\n",
      "Precision:  0.8021\n",
      "Kappa:  0.5337\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAE: {mean_absolute_error(y_pred_gb, y_test): .4f}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_pred_gb, y_test): .4f}\")\n",
    "print(f\"Recall: {recall_score(y_pred_gb, y_test): .4f}\")\n",
    "print(f\"Precision: {precision_score(y_pred_gb, y_test): .4f}\")\n",
    "print(f\"Kappa: {cohen_kappa_score(y_pred_gb, y_test): .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35f135bb-a043-4794-a91e-e8e219e62051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.2310\n",
      "RMSE:  0.4806\n",
      "Recall:  0.7490\n",
      "Precision:  0.8072\n",
      "Kappa:  0.5381\n"
     ]
    }
   ],
   "source": [
    "gb.fit(x_train_norm_df2, y_train2)\n",
    "y_pred_gb2 = gb.predict(x_test_norm_df2)\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(y_pred_gb2, y_test2): .4f}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_pred_gb2, y_test2): .4f}\")\n",
    "print(f\"Recall: {recall_score(y_pred_gb2, y_test2): .4f}\")\n",
    "print(f\"Precision: {precision_score(y_pred_gb2, y_test2): .4f}\")\n",
    "print(f\"Kappa: {cohen_kappa_score(y_pred_gb2, y_test2): .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c259f0b-2629-4bdc-a74f-e3d92e840c8a",
   "metadata": {},
   "source": [
    "### Adaptive Boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abb0dea6-7af0-4321-a907-db5cfdd13fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olgeo\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "ab.fit(x_train_norm_df, y_train)\n",
    "y_pred_ab = ab.predict(x_test_norm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "817f7ddf-aeaa-4ec0-8c78-4edf7f4d8faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.2263\n",
      "RMSE:  0.4757\n",
      "Recall:  0.7623\n",
      "Precision:  0.7935\n",
      "Kappa:  0.5474\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAE: {mean_absolute_error(y_pred_ab, y_test2): .4f}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_pred_ab, y_test2): .4f}\")\n",
    "print(f\"Recall: {recall_score(y_pred_ab, y_test2): .4f}\")\n",
    "print(f\"Precision: {precision_score(y_pred_ab, y_test2): .4f}\")\n",
    "print(f\"Kappa: {cohen_kappa_score(y_pred_ab, y_test2): .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05c08042-a1b9-471a-b189-917ec09f9b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olgeo\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.2248\n",
      "RMSE:  0.4742\n",
      "Recall:  0.7640\n",
      "Precision:  0.7946\n",
      "Kappa:  0.5504\n"
     ]
    }
   ],
   "source": [
    "ab.fit(x_train_norm_df2, y_train2)\n",
    "y_pred_ab2 = ab.predict(x_test_norm_df2)\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(y_pred_ab2, y_test2): .4f}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_pred_ab2, y_test2): .4f}\")\n",
    "print(f\"Recall: {recall_score(y_pred_ab2, y_test2): .4f}\")\n",
    "print(f\"Precision: {precision_score(y_pred_ab2, y_test2): .4f}\")\n",
    "print(f\"Kappa: {cohen_kappa_score(y_pred_ab2, y_test2): .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1c6173-641a-4123-a5d0-ef745a46db93",
   "metadata": {},
   "source": [
    "### Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2aaead38-0fe4-49c4-83e4-9ee11c296b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (KNN):  0.7572\n",
      "Accuracy (Random Forest):  0.7575\n",
      "Accuracy (XGBoost):  0.7668\n",
      "Accuracy (AdaBoost):  0.7737\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy (KNN): {accuracy_score(y_test, y_pred_knn): .4f}')\n",
    "print(f'Accuracy (Random Forest): {accuracy_score(y_test, y_pred_rf): .4f}')\n",
    "print(f'Accuracy (XGBoost): {accuracy_score(y_test, y_pred_gb): .4f}')\n",
    "print(f'Accuracy (AdaBoost): {accuracy_score(y_test, y_pred_ab): .4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5146ed3d-2330-4ab8-9dbe-fae21029c78c",
   "metadata": {},
   "source": [
    "### Recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90e28366-994d-4ec3-a474-b2c66c4f736f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall (KNN):  0.7503\n",
      "Recall (Random Forest):  0.7862\n",
      "Recall (Grad Boost):  0.8021\n",
      "Recall (AdaBoost):  0.7935\n"
     ]
    }
   ],
   "source": [
    "print(f'Recall (KNN): {recall_score(y_test, y_pred_knn): .4f}')\n",
    "print(f'Recall (Random Forest): {recall_score(y_test, y_pred_rf): .4f}')\n",
    "print(f'Recall (Grad Boost): {recall_score(y_test, y_pred_gb): .4f}')\n",
    "print(f'Recall (AdaBoost): {recall_score(y_test, y_pred_ab): .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4992680f-0f47-4200-9e80-f8b5112e0235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For original dataset\n",
      "Recall (KNN):  0.7400\n",
      "Recall (Random Forest):  0.8005\n",
      "Recall (Grad Boost):  0.8072\n",
      "Recall (AdaBoost):  0.7946\n"
     ]
    }
   ],
   "source": [
    "print(\"For original dataset\")\n",
    "print(f'Recall (KNN): {recall_score(y_test2, y_pred_knn2): .4f}')\n",
    "print(f'Recall (Random Forest): {recall_score(y_test, y_pred_rf2): .4f}')\n",
    "print(f'Recall (Grad Boost): {recall_score(y_test2, y_pred_gb2): .4f}')\n",
    "print(f'Recall (AdaBoost): {recall_score(y_test2, y_pred_ab2): .4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db900a3b-1dc7-42be-95ea-ba9d82107718",
   "metadata": {},
   "source": [
    "### Cohen's Kappa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c758053a-6c43-4f9c-ad66-3e7709f75c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the dropped data\n",
      "Kappa (KNN):  0.5143\n",
      "Kappa (Random Forest):  0.5150\n",
      "Kappa (Grad Boost):  0.5337\n",
      "Kappa (AdaBoost):  0.5474\n"
     ]
    }
   ],
   "source": [
    "print(\"For the dropped data\")\n",
    "print(f'Kappa (KNN): {cohen_kappa_score(y_test, y_pred_knn): .4f}')\n",
    "print(f'Kappa (Random Forest): {cohen_kappa_score(y_test, y_pred_rf): .4f}')\n",
    "print(f'Kappa (Grad Boost): {cohen_kappa_score(y_test, y_pred_gb): .4f}')\n",
    "print(f'Kappa (AdaBoost): {cohen_kappa_score(y_test, y_pred_ab): .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4933e8e-8bf2-4cb9-807b-79b099e7641f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the original data\n",
      "Kappa (KNN):  0.4890\n",
      "Kappa (Random Forest):  0.5318\n",
      "Kappa (Grad Boost):  0.5381\n",
      "Kappa (AdaBoost):  0.5504\n"
     ]
    }
   ],
   "source": [
    "print(\"For the original data\")\n",
    "print(f'Kappa (KNN): {cohen_kappa_score(y_test2, y_pred_knn2): .4f}')\n",
    "print(f'Kappa (Random Forest): {cohen_kappa_score(y_test2, y_pred_rf2): .4f}')\n",
    "print(f'Kappa (Grad Boost): {cohen_kappa_score(y_test2, y_pred_gb2): .4f}')\n",
    "print(f'Kappa (AdaBoost): {cohen_kappa_score(y_test2, y_pred_ab2): .4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72772637-0f48-4195-908b-32a375099870",
   "metadata": {},
   "source": [
    "## Optimise KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "828ab191-b28a-42c5-b55a-c822043f8e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, confidence_level, folds):\n",
    "\n",
    "    # First, we define the grid with values to consider when train several possible combinations.\n",
    "    # Now we specify a range/list of values to try for each hyper-parameter, and we let optuna to decide which\n",
    "    # combination to try.\n",
    "    n_neighbors = trial.suggest_int(\"n_neighbors\", 2, 25)\n",
    "    weights = trial.suggest_categorical(\"weights\", ['uniform', 'distance'])\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights)\n",
    "\n",
    "    scorer = make_scorer(recall_score)\n",
    "    # Here the parameter \"cv\" specifies the number of folds K\n",
    "    scores = cross_val_score(knn, x_train_norm_df, y_train, cv=folds, scoring=scorer) # The scores provided will be the R2 on each hold out fold\n",
    "    mean_score = np.mean(scores)\n",
    "    sem = np.std(scores, ddof=1) / np.sqrt(folds)\n",
    "\n",
    "    tc = st.t.ppf(1-((1-confidence_level)/2), df=folds-1)\n",
    "    lower_bound = mean_score - ( tc * sem )\n",
    "    upper_bound = mean_score + ( tc * sem )\n",
    "\n",
    "    # Here, we're storing confidence interval for each trial. It's not possible for the objective function to return\n",
    "    # multiple values as Optuna uses the only returned value to find the best combination of hyperparameters.\n",
    "    trial.set_user_attr(\"CV_score_summary\", [round(lower_bound,4), round(np.mean(scores),4), round(upper_bound,4)])\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2672ded0-e135-416f-b525-1ba1d02eeab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 13:21:37,921] A new study created in memory with name: no-name-885d74f9-99fc-437e-afcd-bb6ea085fd7c\n",
      "[I 2024-12-05 13:21:45,518] Trial 0 finished with value: 0.779943803832737 and parameters: {'n_neighbors': 18, 'weights': 'distance'}. Best is trial 0 with value: 0.779943803832737.\n",
      "[I 2024-12-05 13:21:58,839] Trial 1 finished with value: 0.7963085459310053 and parameters: {'n_neighbors': 17, 'weights': 'uniform'}. Best is trial 1 with value: 0.7963085459310053.\n",
      "[I 2024-12-05 13:22:07,885] Trial 2 finished with value: 0.7790549832757636 and parameters: {'n_neighbors': 17, 'weights': 'distance'}. Best is trial 1 with value: 0.7963085459310053.\n",
      "[I 2024-12-05 13:22:14,263] Trial 3 finished with value: 0.7529139940346237 and parameters: {'n_neighbors': 7, 'weights': 'distance'}. Best is trial 1 with value: 0.7963085459310053.\n",
      "[I 2024-12-05 13:22:25,212] Trial 4 finished with value: 0.7338833369207588 and parameters: {'n_neighbors': 3, 'weights': 'uniform'}. Best is trial 1 with value: 0.7963085459310053.\n",
      "[I 2024-12-05 13:22:31,274] Trial 5 finished with value: 0.7728856226233306 and parameters: {'n_neighbors': 14, 'weights': 'distance'}. Best is trial 1 with value: 0.7963085459310053.\n",
      "[I 2024-12-05 13:22:43,936] Trial 6 finished with value: 0.7815646368671184 and parameters: {'n_neighbors': 24, 'weights': 'uniform'}. Best is trial 1 with value: 0.7963085459310053.\n",
      "[I 2024-12-05 13:22:49,215] Trial 7 finished with value: 0.7229562026587948 and parameters: {'n_neighbors': 4, 'weights': 'distance'}. Best is trial 1 with value: 0.7963085459310053.\n",
      "[I 2024-12-05 13:23:01,802] Trial 8 finished with value: 0.691064686407757 and parameters: {'n_neighbors': 6, 'weights': 'uniform'}. Best is trial 1 with value: 0.7963085459310053.\n",
      "[I 2024-12-05 13:23:08,803] Trial 9 finished with value: 0.7836036202248803 and parameters: {'n_neighbors': 21, 'weights': 'distance'}. Best is trial 1 with value: 0.7963085459310053.\n",
      "[I 2024-12-05 13:23:21,467] Trial 10 finished with value: 0.7465881669622023 and parameters: {'n_neighbors': 12, 'weights': 'uniform'}. Best is trial 1 with value: 0.7963085459310053.\n",
      "[I 2024-12-05 13:23:35,254] Trial 11 finished with value: 0.7991838026027626 and parameters: {'n_neighbors': 23, 'weights': 'uniform'}. Best is trial 11 with value: 0.7991838026027626.\n",
      "[I 2024-12-05 13:23:47,824] Trial 12 finished with value: 0.7815646368671184 and parameters: {'n_neighbors': 24, 'weights': 'uniform'}. Best is trial 11 with value: 0.7991838026027626.\n",
      "[I 2024-12-05 13:24:01,447] Trial 13 finished with value: 0.7740884009990125 and parameters: {'n_neighbors': 20, 'weights': 'uniform'}. Best is trial 11 with value: 0.7991838026027626.\n",
      "[I 2024-12-05 13:24:13,813] Trial 14 finished with value: 0.7893548305539329 and parameters: {'n_neighbors': 13, 'weights': 'uniform'}. Best is trial 11 with value: 0.7991838026027626.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Time taken to find the best combination of hyperparameters among the given ones:  155.8947 seconds\n",
      "\n",
      "\n",
      "The best combination of hyperparameters found was:  {'n_neighbors': 23, 'weights': 'uniform'}\n",
      "The best recall score found was:  0.7992\n"
     ]
    }
   ],
   "source": [
    "confidence_level = 0.95\n",
    "folds = 5\n",
    "\n",
    "start_time = time.time()\n",
    "study = optuna.create_study(direction=\"maximize\") # We want to have the maximum values for the Recall scores\n",
    "study.optimize(lambda trial: objective(trial, confidence_level, folds), n_trials=15)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Time taken to find the best combination of hyperparameters among the given ones: {end_time - start_time: .4f} seconds\")\n",
    "print(\"\\n\")\n",
    "print(\"The best combination of hyperparameters found was: \", study.best_params)\n",
    "print(f\"The best recall score found was: {study.best_value: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ee9aad20-4cf7-48c4-a491-6a7b7550b178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Recall Score confidence interval for the best combination of hyper parameters is: (0.7869, 0.7992, 0.8115)\n"
     ]
    }
   ],
   "source": [
    "results = sorted([(index,\n",
    "  trial.user_attrs['CV_score_summary'][0],\n",
    "  trial.user_attrs['CV_score_summary'][1],\n",
    "  trial.user_attrs['CV_score_summary'][2]) for index, trial in enumerate(study.trials)], key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(f\"The Recall Score confidence interval for the best combination of hyper parameters is: {results[0][1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8a474720-387e-4c50-b8b2-e0e6dd2b4a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:  0.237\n",
      "Test MSE:  0.237\n",
      "Test RMSE: 0.487\n",
      "Test Recall:   0.743\n",
      "Test Precision:  0.803\n",
      "Test Kappa:   0.526\n"
     ]
    }
   ],
   "source": [
    "best_model_knn = KNeighborsClassifier(**study.best_params)\n",
    "best_model_knn.fit(x_train_norm_df, y_train)\n",
    "y_pred_test_df = best_model_knn.predict(x_test_norm_df)\n",
    "\n",
    "print(f\"Test MAE: {mean_absolute_error(y_pred_test_df, y_test): .3f}\")\n",
    "print(f\"Test MSE: {mean_squared_error(y_pred_test_df, y_test): .3f}\")\n",
    "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_pred_test_df, y_test)):.3f}\")\n",
    "print(f\"Test Recall:  {recall_score(y_pred_test_df, y_test): .3f}\")\n",
    "print(f\"Test Precision: {precision_score(y_pred_test_df, y_test): .3f}\")\n",
    "print(f\"Test Kappa:  {cohen_kappa_score(y_pred_test_df, y_test): .3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd8b279-d15d-431e-8c21-9bb238616457",
   "metadata": {},
   "source": [
    "## Optimise random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "250d2e74-4e9b-4a26-bef4-229fe6289947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_objective(trial, confidence_level, folds):\n",
    "    # Hyperparameters to tune\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 150)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 5, 10)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 7)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 7)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", ['sqrt', 'log2'])\n",
    "\n",
    "    # Initialize the RandomForestClassifier with the hyperparameters\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                max_depth=max_depth,\n",
    "                                min_samples_split=min_samples_split,\n",
    "                                min_samples_leaf=min_samples_leaf,\n",
    "                                max_features=max_features,\n",
    "                                random_state=0)\n",
    "\n",
    "    # Scorer for recall\n",
    "    scorer = make_scorer(recall_score)\n",
    "\n",
    "    # Cross-validation scores\n",
    "    scores = cross_val_score(rf, x_train_norm_df, y_train, cv=folds, scoring=scorer)\n",
    "\n",
    "    mean_score = np.mean(scores)\n",
    "    sem = np.std(scores, ddof=1) / np.sqrt(folds)\n",
    "\n",
    "    # Confidence interval (optional)\n",
    "    tc = st.t.ppf(1 - ((1 - confidence_level) / 2), df=folds - 1)\n",
    "    lower_bound = mean_score - (tc * sem)\n",
    "    upper_bound = mean_score + (tc * sem)\n",
    "\n",
    "    # Store confidence interval for each trial\n",
    "    trial.set_user_attr(\"CV_score_summary\", [round(lower_bound, 4), round(np.mean(scores), 4), round(upper_bound, 4)])\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "463a8481-5361-4f4c-9801-c37a51cd409b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 14:07:14,453] A new study created in memory with name: no-name-0bdefaf2-ba66-480c-8b2c-d16679cf5ec7\n",
      "[I 2024-12-05 14:07:36,338] Trial 0 finished with value: 0.8248028863401083 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 0 with value: 0.8248028863401083.\n",
      "[I 2024-12-05 14:07:51,347] Trial 1 finished with value: 0.8247504074290459 and parameters: {'n_estimators': 57, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8248028863401083.\n",
      "[I 2024-12-05 14:08:01,345] Trial 2 finished with value: 0.8198360854012279 and parameters: {'n_estimators': 58, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8248028863401083.\n",
      "[I 2024-12-05 14:08:30,260] Trial 3 finished with value: 0.8241228881167382 and parameters: {'n_estimators': 96, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 0 with value: 0.8248028863401083.\n",
      "[I 2024-12-05 14:08:44,588] Trial 4 finished with value: 0.8175880610477332 and parameters: {'n_estimators': 77, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8248028863401083.\n",
      "[I 2024-12-05 14:09:06,508] Trial 5 finished with value: 0.8230773141457315 and parameters: {'n_estimators': 108, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.8248028863401083.\n",
      "[I 2024-12-05 14:09:28,415] Trial 6 finished with value: 0.8226594371500123 and parameters: {'n_estimators': 135, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 0 with value: 0.8248028863401083.\n",
      "[I 2024-12-05 14:09:57,254] Trial 7 finished with value: 0.8254822422434736 and parameters: {'n_estimators': 108, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 7 with value: 0.8254822422434736.\n",
      "[I 2024-12-05 14:10:08,838] Trial 8 finished with value: 0.8245935036847986 and parameters: {'n_estimators': 57, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.8254822422434736.\n",
      "[I 2024-12-05 14:10:20,530] Trial 9 finished with value: 0.818842566683408 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 7 with value: 0.8254822422434736.\n",
      "[I 2024-12-05 14:10:55,626] Trial 10 finished with value: 0.826057350976634 and parameters: {'n_estimators': 141, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 10 with value: 0.826057350976634.\n",
      "[I 2024-12-05 14:11:31,651] Trial 11 finished with value: 0.8265278572136294 and parameters: {'n_estimators': 150, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 11 with value: 0.8265278572136294.\n",
      "[I 2024-12-05 14:12:07,219] Trial 12 finished with value: 0.8242797371954531 and parameters: {'n_estimators': 147, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 11 with value: 0.8265278572136294.\n",
      "[I 2024-12-05 14:12:43,770] Trial 13 finished with value: 0.825900501897919 and parameters: {'n_estimators': 128, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 11 with value: 0.8265278572136294.\n",
      "[I 2024-12-05 14:13:17,245] Trial 14 finished with value: 0.824541188770333 and parameters: {'n_estimators': 148, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 11 with value: 0.8265278572136294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time taken to find the best combination of hyperparameters:  362.7952 seconds\n",
      "\n",
      "\n",
      "The best combination of hyperparameters found was:  {'n_estimators': 150, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'log2'}\n",
      "The best recall score found was:  0.8265\n"
     ]
    }
   ],
   "source": [
    "confidence_level = 0.95\n",
    "folds = 5\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Create Optuna study for maximizing recall score\n",
    "study_rf = optuna.create_study(direction=\"maximize\")  # Maximizing recall score\n",
    "study_rf.optimize(lambda trial: rf_objective(trial, confidence_level, folds), n_trials=15)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Print out the time taken\n",
    "print(f\"\\nTime taken to find the best combination of hyperparameters: {end_time - start_time: .4f} seconds\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print out the best combination of hyperparameters\n",
    "print(\"The best combination of hyperparameters found was: \", study_rf.best_params)\n",
    "print(f\"The best recall score found was: {study_rf.best_value: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "68452f4b-d75b-457f-8cee-f6950283157d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:  0.224\n",
      "Test MSE:  0.224\n",
      "Test RMSE: 0.473\n",
      "Test Recall:   0.751\n",
      "Test Precision:  0.826\n",
      "Test F1 Score:   0.786\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the best hyperparameters\n",
    "best_rf = RandomForestClassifier(**study_rf.best_params, random_state=0)\n",
    "best_rf.fit(x_train_norm_df, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = best_rf.predict(x_test_norm_df)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "print(f\"Test MAE: {mean_absolute_error(y_pred_rf, y_test): .3f}\")\n",
    "print(f\"Test MSE: {mean_squared_error(y_pred_rf, y_test): .3f}\")\n",
    "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_pred_rf, y_test)):.3f}\")\n",
    "print(f\"Test Recall:  {recall_score(y_pred_rf, y_test): .3f}\")\n",
    "print(f\"Test Precision: {precision_score(y_pred_rf, y_test): .3f}\")\n",
    "print(f\"Test F1 Score:  {f1_score(y_pred_rf, y_test): .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab8e46-86cc-4f15-b41d-0282d84f0f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
